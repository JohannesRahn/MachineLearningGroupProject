{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2540aaf-fc28-463b-ae53-9f3af7f6b760",
   "metadata": {},
   "source": [
    "## Importing Packages "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549e96ab-95ff-4897-8d8c-4a7e97ebfb8b",
   "metadata": {},
   "source": [
    "### Network Analytics\n",
    "\n",
    "In the following code, we create an undirected graph representing relationships between users based on the video games they've reviewed. Each vertex in the graph corresponds to a unique user, and an edge is added between two vertices if they have reviewed the same game. This graph allows us to analyze relationships between users and potentially discover interesting patterns, such as clusters of users who review similar games, highly connected users, or correlations between graph properties and other features of the dataframe.\n",
    "\n",
    "The graph is being used to find a similar user to a user that only has one review. The most similar user must have at least 2 different games reviewed.\n",
    "The function <b>find_most_similar_user</b> takes a user ID, a graph, and an optional parameter min_edges as inputs, and returns the ID of the user in the graph that is most similar to the input user based on their common game reviews with other users. The function finds the input user's neighbors between the input user and their neighbors, filters the candidate vertices based on the input user's y value and minimum degree, and then finds the candidate vertex with the most common game reviews with the input user's neighbors. If there are ties, the function returns the user with the most number of connections to other neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacd787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import igraph as ig\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pickle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58944f8-dc00-4a5c-988c-55a0904080f7",
   "metadata": {},
   "source": [
    "## Reading DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4cccfbe-8970-4925-85a4-e96b4d687f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>y</th>\n",
       "      <th>app_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>304390</td>\n",
       "      <td>1098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>306130</td>\n",
       "      <td>17622</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>238960</td>\n",
       "      <td>33969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>730</td>\n",
       "      <td>24431</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>255710</td>\n",
       "      <td>125959</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_id      y  app_id  user_id  reviews\n",
       "0          1  False  304390     1098        1\n",
       "1          5   True  306130    17622        4\n",
       "2          6   True  238960    33969        1\n",
       "3          7  False     730    24431        2\n",
       "4          8   True  255710   125959        3"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimizing datatypes for efficient DF storage\n",
    "data_types = {\n",
    "    'review_id': 'int32',\n",
    "    'y': 'bool',\n",
    "    'app_id': 'int32',\n",
    "    'user_id': 'int32',\n",
    "    'reviews': 'int16'\n",
    "}\n",
    "# Only importing necessary columns\n",
    "final_df = pd.read_csv(\"../data/final_df.csv\", dtype = data_types, usecols=data_types.keys())\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "108f8fb7-9aa1-48fb-b8fd-21fea14755d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_total_samples = 100000\n",
    "\n",
    "neg_pos_ratio = final_df['y'].value_counts()[1] / final_df['y'].value_counts()[0]\n",
    "# Determine Number of False and Number of True Samples\n",
    "n_false_samples = int(n_total_samples * neg_pos_ratio)\n",
    "n_true_samples = n_total_samples - n_false_samples\n",
    "\n",
    "# Sample On this Basis \n",
    "false_samples = final_df[final_df['y'] == False].sample(n_false_samples, random_state=70)\n",
    "true_samples = final_df[final_df['y'] == True].sample(n_true_samples, random_state=70)\n",
    "\n",
    "final_sample_df = pd.concat([false_samples, true_samples])\n",
    "\n",
    "# shuffle the data\n",
    "final_df = final_sample_df.sample(frac=1, random_state=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d89e7bec-e3f9-4337-8d44-b95a82515390",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5baf0b23-d4b5-47c2-b574-00eaf32b9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-distributed version\n",
    "def add_edges_optimized(graph, common_user_df, final_df):\n",
    "    edges = []\n",
    "    edge_common_games = []\n",
    "    edge_columns = {col: [] for col in ['y_x', 'user_id_x', 'review_id_x']}\n",
    "    \n",
    "    grouped_common_user_df = common_user_df.groupby(['user_id_x', 'user_id_y'])\n",
    "    \n",
    "    for (user_id_source, user_id_target), group in grouped_common_user_df:\n",
    "        source_vertex_id = user_id_to_vertex_id[user_id_source]\n",
    "        target_vertex_id = user_id_to_vertex_id[user_id_target]\n",
    "\n",
    "        common_games = group['app_id'].tolist()\n",
    "        columns = {col: group[col].tolist() for col in edge_columns.keys()}\n",
    "\n",
    "        edges.append((source_vertex_id, target_vertex_id))\n",
    "        edge_common_games.append(common_games)\n",
    "\n",
    "        for col in edge_columns:\n",
    "            edge_columns[col].extend(columns[col])\n",
    "\n",
    "    graph.add_edges(edges)\n",
    "    graph.es[\"common_game_ids\"] = edge_common_games\n",
    "    for col in edge_columns:\n",
    "        graph.es[col[:-2]] = edge_columns[col]  # Remove the '_x' suffix for the edge attribute names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f351f3d3-30d1-43c5-aff7-2c024c4c31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_user_ids = final_df['user_id'].unique()\n",
    "\n",
    "user_id_to_user_info = {user_id: user_info for user_id, user_info in zip(final_df['user_id'], final_df.to_dict('records'))}\n",
    "\n",
    "user_id_to_vertex_id = {user_id: idx for idx, user_id in enumerate(unique_user_ids)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2c16d7-c071-45c9-bbdb-4301b486b62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing undirected graph\n",
    "G = ig.Graph(directed=False)\n",
    "\n",
    "G.add_vertices(len(unique_user_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c5455d4-6510-4b90-9f0e-72ef557e22f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G.vs[\"user_info\"] = [user_id_to_user_info[user_id] for user_id in unique_user_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afafeb90-6b15-4541-8a4d-00e53a74f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_columns = ['y', 'user_id', 'review_id']\n",
    "\n",
    "for col in review_columns:\n",
    "    G.vs[col] = [user_info[col] for user_info in G.vs[\"user_info\"]]\n",
    "\n",
    "app_user_pairs = final_df[['app_id', 'user_id', 'y', 'review_id']]\n",
    "\n",
    "common_user_df = app_user_pairs.merge(app_user_pairs, on='app_id')\n",
    "\n",
    "common_user_df = common_user_df[common_user_df['user_id_x'] < common_user_df['user_id_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b290cb4-78a5-48b2-9c47-ab0a637a0d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the edges to the graph\n",
    "add_edges_optimized(G, common_user_df, final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fa694-690c-4bb1-a238-a93b5ec81d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/user_graph.pickle\", \"wb\") as f:\n",
    "    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad0a1b0c-1f7d-4a4a-975f-fad2ce4632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read graph from file:\n",
    "with open(\"../data/user_graph.pickle\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3de27cd-99f6-4a44-9a69-72f20dc3db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case reviews is not existing in the df\n",
    "user_reviews = final_df.set_index('user_id')['reviews'].to_dict()\n",
    "\n",
    "# Now, iterate over the vertices of the graph\n",
    "for v in G.vs:\n",
    "    user_id = v[\"user_id\"]\n",
    "    # If the user_id of the vertex is in the dictionary, add the reviews attribute\n",
    "    if user_id in user_reviews:\n",
    "        v[\"reviews\"] = user_reviews[user_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42fd2ae7-717e-4418-aa90-66eda737207b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_most_similar_user_by_connections(user_id, graph):\n",
    "    user_vertex_id = user_id_to_vertex_id[user_id]\n",
    "    user_vertex = graph.vs[user_vertex_id]\n",
    "    user_y = user_vertex['y']\n",
    "    \n",
    "    max_connections = 1\n",
    "    most_connected_neighbor = None\n",
    "    \n",
    "    for neighbor_id in graph.neighbors(user_vertex_id):\n",
    "        neighbor_vertex = graph.vs[neighbor_id]\n",
    "        if neighbor_vertex['y'] != user_y:\n",
    "            continue\n",
    "        if neighbor_vertex['reviews'] <= 1:\n",
    "            continue\n",
    "            \n",
    "        connections = len(set(graph.neighbors(user_vertex_id)).intersection(graph.neighbors(neighbor_id)))\n",
    "        \n",
    "        if connections > max_connections:\n",
    "            max_connections = connections\n",
    "            most_connected_neighbor = neighbor_vertex\n",
    "            \n",
    "    return most_connected_neighbor[\"user_id\"] if most_connected_neighbor else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2244580a-41d8-42f5-a174-b10d4ab66e3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_most_similar_user_by_connections(user_id, graph):\n",
    "    user_vertex_id = user_id_to_vertex_id[user_id]\n",
    "    user_vertex = graph.vs[user_vertex_id]\n",
    "    user_y = user_vertex['y']\n",
    "    \n",
    "    max_connections = -1\n",
    "    most_connected_neighbor = None\n",
    "    \n",
    "    user_neighbors = set(graph.neighbors(user_vertex_id))\n",
    "\n",
    "    for neighbor_id in user_neighbors:\n",
    "        neighbor_vertex = graph.vs[neighbor_id]\n",
    "        if neighbor_vertex['y'] != user_y:\n",
    "            continue\n",
    "            \n",
    "        neighbor_edges = graph.es[graph.incident(neighbor_id)]\n",
    "        unique_app_ids = set(e[\"common_game_ids\"][0] for e in neighbor_edges)\n",
    "        if len(unique_app_ids) < 2:\n",
    "            continue\n",
    "\n",
    "        neighbor_neighbors = set(graph.neighbors(neighbor_id))\n",
    "        connections = len(user_neighbors.intersection(neighbor_neighbors))\n",
    "        \n",
    "        if connections > max_connections:\n",
    "            max_connections = connections\n",
    "            most_connected_neighbor = neighbor_vertex\n",
    "\n",
    "    return most_connected_neighbor[\"user_id\"] if most_connected_neighbor else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df4e76ef-92f9-4a48-9c7e-d696ff29b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a count of the unique values in the 'name' column\n",
    "value_counts = final_df['user_id'].value_counts()\n",
    "\n",
    "# create a Boolean mask to select only the values that appear once\n",
    "mask = value_counts == 1\n",
    "\n",
    "# use the Boolean mask to filter the DataFrame\n",
    "one_review_users = final_df[final_df['user_id'].isin(value_counts[mask].index)]['user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db61050-fd61-45e7-bf7c-521dc0f385b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_most_similar_user = {}\n",
    "count = 0\n",
    "\n",
    "for user in one_review_users:\n",
    "    dict_most_similar_user[user] = find_most_similar_user_by_connections(user, G)\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc22ba0-f472-4ac3-9274-966234752b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/similar_users.csv', 'w') as f:\n",
    "    f.write(\"%s, %s\\n\" % (\"user_id\", \"similar_user\"))\n",
    "    for key in dict_most_similar_user.keys():\n",
    "        f.write(\"%s, %s\\n\" % (key, dict_most_similar_user[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d256d-5875-4262-a218-db3f0672e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ig.plot(G))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
